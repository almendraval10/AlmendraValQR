{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GROUP 1 - Python\n",
    "* DEL CARPIO CUENCA, GABRIEL SEBASTIAN\n",
    "* ESPINOSA CALDERON, MAURICIO GUSTAVO\n",
    "* JAIME MARTINEZ, KEVIN OSWALDO\n",
    "* MELLIZO ANTAZU, MILAGROS ESTEFANY\n",
    "* QUISPE ROBLADILLO, ALMENDRA VALERIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from formulaic import Formula\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the data set. Make sure the column names are imported as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>lwage</th>\n",
       "      <th>sex</th>\n",
       "      <th>shs</th>\n",
       "      <th>hsg</th>\n",
       "      <th>scl</th>\n",
       "      <th>clg</th>\n",
       "      <th>ad</th>\n",
       "      <th>mw</th>\n",
       "      <th>so</th>\n",
       "      <th>we</th>\n",
       "      <th>ne</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>exp4</th>\n",
       "      <th>occ</th>\n",
       "      <th>occ2</th>\n",
       "      <th>ind</th>\n",
       "      <th>ind2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.615385</td>\n",
       "      <td>2.263364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.2401</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8370.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.076923</td>\n",
       "      <td>3.872802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.61</td>\n",
       "      <td>29.791</td>\n",
       "      <td>92.3521</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5070.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.057692</td>\n",
       "      <td>2.403126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.24</td>\n",
       "      <td>5.832</td>\n",
       "      <td>10.4976</td>\n",
       "      <td>6260.0</td>\n",
       "      <td>19</td>\n",
       "      <td>770.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.942308</td>\n",
       "      <td>2.634928</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>15.625</td>\n",
       "      <td>39.0625</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6990.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.846154</td>\n",
       "      <td>3.361977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.84</td>\n",
       "      <td>10.648</td>\n",
       "      <td>23.4256</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>14.769231</td>\n",
       "      <td>2.692546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4970.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>23.076923</td>\n",
       "      <td>3.138833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.728</td>\n",
       "      <td>2.0736</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>13</td>\n",
       "      <td>8680.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>38.461538</td>\n",
       "      <td>3.649659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.331</td>\n",
       "      <td>1.4641</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>32.967033</td>\n",
       "      <td>3.495508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6570.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>17.307692</td>\n",
       "      <td>2.851151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.744</td>\n",
       "      <td>3.8416</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7460.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5150 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           wage     lwage  sex  shs  hsg  scl  clg   ad   mw   so   we   ne  \\\n",
       "0      9.615385  2.263364  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1     48.076923  3.872802  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2     11.057692  2.403126  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3     13.942308  2.634928  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
       "4     28.846154  3.361977  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "...         ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5145  14.769231  2.692546  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "5146  23.076923  3.138833  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "5147  38.461538  3.649659  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "5148  32.967033  3.495508  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "5149  17.307692  2.851151  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "      exp1  exp2    exp3     exp4     occ  occ2     ind  ind2  \n",
       "0      7.0  0.49   0.343   0.2401  3600.0    11  8370.0    18  \n",
       "1     31.0  9.61  29.791  92.3521  3050.0    10  5070.0     9  \n",
       "2     18.0  3.24   5.832  10.4976  6260.0    19   770.0     4  \n",
       "3     25.0  6.25  15.625  39.0625   420.0     1  6990.0    12  \n",
       "4     22.0  4.84  10.648  23.4256  2015.0     6  9470.0    22  \n",
       "...    ...   ...     ...      ...     ...   ...     ...   ...  \n",
       "5145   9.0  0.81   0.729   0.6561  4700.0    16  4970.0     9  \n",
       "5146  12.0  1.44   1.728   2.0736  4110.0    13  8680.0    20  \n",
       "5147  11.0  1.21   1.331   1.4641  1550.0     4  3680.0     6  \n",
       "5148  10.0  1.00   1.000   1.0000  2920.0     9  6570.0    11  \n",
       "5149  14.0  1.96   2.744   3.8416  1610.0     5  7460.0    14  \n",
       "\n",
       "[5150 rows x 20 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "data = pd.read_csv('wage2015_subsample_inference.csv') \n",
    "data = data.drop('rownames',axis=1)\n",
    "data\n",
    "#list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. As in Group Assignment 1, generate the extra-flexible model. This means that it contains all two-way interactions between the experience polynomials and the indicator variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Generate the array for the outcome variable $Y$ and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"lwage\"].to_numpy().reshape(-1, 1)\n",
    "# Normalize Y\n",
    "y_normalized = StandardScaler().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_normalized)\n",
    "#print(y_normalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Generate the array for the predictors \n",
    "$X$ (do not generate an intercept) and normalize its colums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5150, 979)\n"
     ]
    }
   ],
   "source": [
    "# Matrix\n",
    "extra_flexible = Formula(\"sex + (exp1 + exp2 + exp3 + exp4 + hsg + scl + clg + ad + so + we + ne + C(occ2) + C(ind2)) ^ 2\").get_model_matrix(data)\n",
    "# Eliminate intercept\n",
    "extra_flexible = extra_flexible.loc[:, extra_flexible.columns != 'Intercept']\n",
    "# conitnue variable\n",
    "cont = ['exp1', 'exp2', 'exp3', 'exp4']\n",
    "\n",
    "# Normalization\n",
    "extra_flexible[cont] = StandardScaler().fit_transform(extra_flexible[cont])\n",
    "# Final array\n",
    "X_normalized = extra_flexible.to_numpy()\n",
    "\n",
    "print(X_normalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split between training and testing samples. The testing sample should be 10% of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, train_size = .9, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the Lasso Cross-Validation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Program a function that generates a logarithmically spaced grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_spaced_grid(lower_bound, upper_bound, num_points):\n",
    "    log_lower = np.log(lower_bound)\n",
    "    log_upper = np.log(upper_bound)\n",
    "    log_grid = np.linspace(log_lower, log_upper, num_points)\n",
    "    return np.exp(log_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Program a function to generate $k$ folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_folds(X, k):\n",
    "    # Number of samples\n",
    "    total_samples = X.shape[0] \n",
    "    \n",
    "    # Size of each fold\n",
    "    fold_sizes = np.full(k, total_samples // k, dtype=int)\n",
    "    fold_sizes[:total_samples % k] += 1  \n",
    "    \n",
    "    # Generate shuffled indices\n",
    "    indices = np.arange(total_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    folds = []  # Store folds here\n",
    "    current_index = 0\n",
    "    \n",
    "    # Create the folds\n",
    "    for size in fold_sizes:\n",
    "        start, end = current_index, current_index + size\n",
    "        mask = np.zeros(total_samples, dtype=bool)\n",
    "        mask[indices[start:end]] = True\n",
    "        folds.append(mask)\n",
    "        current_index = end\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Program a function that integrates those that you programmed in the last two items to find the value of \n",
    "$λ$ that minimizes the testing mean square error across folds. It should take the following inputs:\n",
    "\n",
    "* Y: an array for the outcome variable.\n",
    "* X: an array of predictors.\n",
    "* lambda_bounds: the lower and upper bounds of the grid of lambda values.\n",
    "* k: number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_lambda(Y, X, lambda_bounds, k):\n",
    "    # Grid of lambda values\n",
    "    lambdas = log_spaced_grid(lambda_bounds[0], lambda_bounds[1], num_points=100)\n",
    "    \n",
    "    # k folds \n",
    "    folds = create_k_folds(X, k)\n",
    "    \n",
    "    # Array to store MSE values\n",
    "    all_mse = np.zeros((len(lambdas), k))\n",
    "    \n",
    "    # Evaluating each lambda\n",
    "    for i, lambda_val in enumerate(lambdas):\n",
    "        for j, fold in enumerate(folds):\n",
    "            # Split data into training and testing sets\n",
    "            X_train, X_test = X[~fold], X[fold]\n",
    "            Y_train, Y_test = Y[~fold], Y[fold]\n",
    "            \n",
    "            # Fit Lasso model\n",
    "            model = Lasso(alpha=lambda_val, fit_intercept=True)\n",
    "            model.fit(X_train, Y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            Y_pred = model.predict(X_test)\n",
    "            all_mse[i, j] = np.mean((Y_test - Y_pred) ** 2)\n",
    "\n",
    "    # MSE \n",
    "    avg_mse = np.mean(all_mse, axis=1)\n",
    "    \n",
    "    # optimal lambda\n",
    "    optimal_index = np.argmin(avg_mse)\n",
    "    optimal_lambda_value = lambdas[optimal_index]\n",
    "    optimal_model = Lasso(alpha=optimal_lambda_value, fit_intercept=True)\n",
    "    optimal_model.fit(X, Y)\n",
    "    \n",
    "    result = {\n",
    "        'optimal_lambda': optimal_lambda_value,\n",
    "        'optimal_coef': optimal_model.coef_,\n",
    "        'all_lambdas': lambdas,\n",
    "        'all_mse': avg_mse\n",
    "    }\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Program a function for predicting the outcome variable through model estimated with the optimal lambda. It should take as inputs\n",
    "* optimal_model: A dictionary with the values outputed by the function defined for the previous point.\n",
    "* X: an array of predictors.\n",
    "\n",
    "The output should be an array of predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_predict(optimal_model, X):\n",
    "    \n",
    "    optimal_lambda = optimal_model.get('optimal_lambda')\n",
    "    optimal_coef = optimal_model.get('optimal_coef')\n",
    "    lasso_model = Lasso(alpha=optimal_lambda, fit_intercept=True)\n",
    "    \n",
    "    lasso_model.coef_ = optimal_coef  \n",
    "    lasso_model.intercept_ = 0       # no intercept\n",
    "    \n",
    "    # Predictions\n",
    "    predicciones = lasso_model.predict(X)\n",
    "    \n",
    "    return predicciones  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying the Lasso Cross-Validation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Fit a simple OLS model with the training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS model\n",
    "ols = LinearRegression().fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y predicted\n",
    "y_pred = ols.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (OLS): 0.2394\n",
      "R^2 (OLS): 0.2322\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the ols model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE (OLS): {mse:.4f}\")\n",
    "print(f\"R^2 (OLS): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Find the optimal lambda and its related coefficients with the function programmed in 3. and the training sample. Print the lambda and the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_bounds = (0.1, 1)\n",
    "result = opt_lambda(y_train, X_train, lambda_bounds, k=5)\n",
    "# Results\n",
    "print(f\"Optimal lambda: {result['optimal_lambda']}\")\n",
    "print(f\"Coefficients: {result['optimal_coef']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Use each language's hdm package to fit a Lasso model with the theoretical optimal lambda value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'hdmpy'...\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/maxhuppertz/hdmpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\almen\\OneDrive\\Escritorio\\ABC_SUBIR\\CausalAI-Course\\Labs\\Assignment\\Assigment_2\\hdmpy\")\n",
    "\n",
    "import hdmpy as hdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lambda = result['optimal_lambda']  \n",
    "\n",
    "# Lasso model\n",
    "lasso_hdm = hdm.LassoHDM(alpha=optimal_lambda)  \n",
    "lasso_hdm.fit(X_train, y_train)  \n",
    "\n",
    "# Coefficients\n",
    "coefficients = lasso_hdm.coef_  \n",
    "\n",
    "# Results\n",
    "print(f\"Optimal lambda: {optimal_lambda}\")  \n",
    "print(f\"Coefficients from hdm Lasso model: {coefficients}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Report the testing MSE and  $R^2$ for the OLS model and, the cross-validation lambda Lasso model, and the hdm theoretical lambda model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (OLS): 0.2394\n",
      "R^2 (OLS): 0.2322\n"
     ]
    }
   ],
   "source": [
    "# Metrics:\n",
    "# OLS\n",
    "print(f\"MSE (OLS): {mse:.4f}\")\n",
    "print(f\"R^2 (OLS): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso cross validation\n",
    "mse_lasso_cv = mean_squared_error(y_test, lasso_predict(result, X_test))\n",
    "r2_lasso_cv = r2_score(y_test, lasso_predict(result, X_test))\n",
    "print(f\"MSE (Lasso CV): {mse_lasso_cv:.4f}\")\n",
    "print(f\"R^2 (Lasso CV): {r2_lasso_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso  hdmpy\n",
    "y_pred_lasso_hdm = lasso_hdm.predict(X_test)\n",
    "mse_lasso_hdm = mean_squared_error(y_test, y_pred_lasso_hdm)\n",
    "r2_lasso_hdm = r2_score(y_test, y_pred_lasso_hdm)\n",
    "print(f\"MSE (Lasso HDM): {mse_lasso_hdm:.4f}\")\n",
    "print(f\"R^2 (Lasso HDM): {r2_lasso_hdm:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otree_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
